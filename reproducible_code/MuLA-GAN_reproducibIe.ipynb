{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG612HX9Q1m-",
        "outputId": "0492b8f6-41d7-408a-8fb1-a87913f8d854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MuLA_GAN'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 125 (delta 30), reused 78 (delta 15), pack-reused 28 (from 1)\u001b[K\n",
            "Receiving objects: 100% (125/125), 144.94 MiB | 34.59 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "/content/MuLA_GAN\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 1. Clone the repository\n",
        "!git clone https://github.com/AhsanBaidar/MuLA_GAN.git\n",
        "\n",
        "# 2. Navigate into the folder\n",
        "%cd MuLA_GAN\n",
        "\n",
        "# 3. Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 1. USER CONFIGURATION: SET DATASET PATHS\n",
        "# ==========================================================\n",
        "# The base folder of your dataset (e.g., UIEB, LSUI, etc.)\n",
        "BASE_PATH = '/content/drive/MyDrive/LSUI_Split'\n",
        "\n",
        "# Relative subfolders for Train/Test\n",
        "TRAIN_A = 'train/trainA'\n",
        "TRAIN_B = 'train/trainB'\n",
        "TEST_A = 'test/testA'\n",
        "TEST_B = 'test/testB'\n",
        "\n",
        "# Name for your experiment folder\n",
        "DATASET_NAME = \"LSUI-Split\""
      ],
      "metadata": {
        "id": "xckYpu-Kt-Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Create directory structure\n",
        "os.makedirs(\"configs\", exist_ok=True)\n",
        "os.makedirs(\"utils\", exist_ok=True)\n",
        "\n",
        "# 2. Generate the YAML for the training script\n",
        "yaml_content = f\"\"\"\n",
        "dataset_path: '{BASE_PATH}'\n",
        "TRAIN_INPUT: '{TRAIN_A}'\n",
        "TRAIN_GT: '{TRAIN_B}'\n",
        "TEST_INPUT: '{TEST_A}'\n",
        "TEST_GT: '{TEST_B}'\n",
        "dataset_name: \"{DATASET_NAME}\"\n",
        "\n",
        "im_width: 256\n",
        "im_height: 256\n",
        "chans: 3\n",
        "\n",
        "MODEL_NAME: 'MuLA_GAN'\n",
        "GENERATOR: 'mula_gan_g'\n",
        "DISCRIMINATOR: 'mula_gan_d'\n",
        "\n",
        "BATCH_SIZE: 8\n",
        "NUM_EPOCHS: 200\n",
        "LR_G: 0.0002\n",
        "LR_D: 0.0002\n",
        "B1: 0.5\n",
        "B2: 0.999\n",
        "WEIGHT_DECAY: 0.0001\n",
        "LAMBDA_L1: 100\n",
        "LAMBDA_ADV: 1\n",
        "LAMBDA_PERCEPTUAL: 10\n",
        "\n",
        "ckpt_interval: 20\n",
        "SAMPLE_INTERVAL: 1000\n",
        "LOG_INTERVAL: 50\n",
        "val_interval: 1000\n",
        "\n",
        "CHECKPOINT_DIR: 'checkpoints'\n",
        "SAMPLE_DIR: 'samples'\n",
        "RESULTS_PATH: 'results'\n",
        "\"\"\"\n",
        "\n",
        "with open(\"configs/train_MuLA-GAN.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# 3. Create the Dataloader file\n",
        "with open(\"utils/data_utils.py\", \"w\") as f:\n",
        "    f.write(\"\"\"import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import yaml\n",
        "\n",
        "class Dataloader(Dataset):\n",
        "    def __init__(self, root, dataset_name, transforms_=None, config_path=\"configs/train_MuLA-GAN.yaml\"):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        with open(config_path) as f:\n",
        "            cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        input_path = os.path.join(cfg.get(\"dataset_path\", root), cfg.get(\"TRAIN_INPUT\"))\n",
        "        gt_path = os.path.join(cfg.get(\"dataset_path\", root), cfg.get(\"TRAIN_GT\"))\n",
        "        self.filesA = sorted(glob.glob(input_path + \"/*.*\"))\n",
        "        self.filesB = sorted(glob.glob(gt_path + \"/*.*\"))\n",
        "        self.len = min(len(self.filesA), len(self.filesB))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        idx = index % self.len\n",
        "        img_A = Image.open(self.filesA[idx]).convert('RGB')\n",
        "        img_B = Image.open(self.filesB[idx]).convert('RGB')\n",
        "        return {\"A\": self.transform(img_A), \"B\": self.transform(img_B)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\"\"\")\n",
        "\n",
        "print(f\" Setup Complete. Files created for dataset: {DATASET_NAME}\")"
      ],
      "metadata": {
        "id": "XzXy7Ygxt_3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will use the config created in Cell 2\n",
        "!python train_MuLA_GAN.py"
      ],
      "metadata": {
        "id": "DIOVh6NGuFFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which epoch weight to test (e.g., the last one)\n",
        "EPOCH_TO_TEST = 300\n",
        "\n",
        "weights_path = f\"checkpoints/{DATASET_NAME}/generator_{EPOCH_TO_TEST}.pth\"\n",
        "test_data_path = f\"{BASE_PATH}/{TEST_A}\"\n",
        "output_dir = f\"./output_{DATASET_NAME.lower()}/\"\n",
        "\n",
        "!python test.py \\\n",
        "  --weights_path \"{weights_path}\" \\\n",
        "  --data_dir \"{test_data_path}\" \\\n",
        "  --sample_dir \"{output_dir}\""
      ],
      "metadata": {
        "id": "pxXf7wU8uSHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Evaluation directory if it doesn't exist\n",
        "os.makedirs(\"Evaluation\", exist_ok=True)\n",
        "\n",
        "# Generate the script with the variables from Cell 1\n",
        "evaluation_script = f\"\"\"\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from os.path import join, exists\n",
        "from ntpath import basename\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from Evaluation.imqual_utils import getSSIM, getPSNR\n",
        "except ImportError:\n",
        "    try:\n",
        "         from imqual_utils import getSSIM, getPSNR\n",
        "    except ImportError as e:\n",
        "        print(f\"Error importing imqual_utils: {{e}}\")\n",
        "        exit()\n",
        "\n",
        "def SSIMs_PSNRs(gtr_dir, gen_dir, im_res=(256, 256)):\n",
        "    gtr_paths = sorted(glob(join(gtr_dir, \"*.*\")))\n",
        "    ssims, psnrs = [], []\n",
        "    processed_count = 0\n",
        "\n",
        "    if not gtr_paths:\n",
        "        print(f\"Error: No images found in {{gtr_dir}}\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    for gtr_path in gtr_paths:\n",
        "        gtr_f_base = basename(gtr_path).split('.')[0]\n",
        "        # Check common formats\n",
        "        gen_path = None\n",
        "        for ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
        "            check_path = join(gen_dir, gtr_f_base + ext)\n",
        "            if exists(check_path):\n",
        "                gen_path = check_path\n",
        "                break\n",
        "\n",
        "        if gen_path:\n",
        "            processed_count += 1\n",
        "            try:\n",
        "                r_im = Image.open(gtr_path).resize(im_res).convert('RGB')\n",
        "                g_im = Image.open(gen_path).resize(im_res).convert('RGB')\n",
        "\n",
        "                ssim_val = getSSIM(np.array(r_im), np.array(g_im))\n",
        "                if np.isfinite(ssim_val): ssims.append(ssim_val)\n",
        "\n",
        "                psnr_val = getPSNR(np.array(r_im.convert(\"L\")), np.array(g_im.convert(\"L\")))\n",
        "                if np.isfinite(psnr_val): psnrs.append(psnr_val)\n",
        "            except Exception as e:\n",
        "                 print(f\"Error processing {{basename(gtr_path)}}: {{e}}\")\n",
        "\n",
        "    return np.array(ssims), np.array(psnrs)\n",
        "\n",
        "# Using variables defined in Cell 1\n",
        "gtr_dir = \"{BASE_PATH}/{TEST_B}\"\n",
        "gen_dir = \"./output_{DATASET_NAME.lower()}/\"\n",
        "\n",
        "SSIM_measures, PSNR_measures = SSIMs_PSNRs(gtr_dir, gen_dir)\n",
        "\n",
        "if len(SSIM_measures) > 0:\n",
        "    print(f\"\\\\n--- {{os.path.basename(gen_dir)}} Results ---\")\n",
        "    print(f\"SSIM ({{len(SSIM_measures)}} samples) -> Mean: {{np.mean(SSIM_measures):.4f}}\")\n",
        "    print(f\"PSNR ({{len(PSNR_measures)}} samples) -> Mean: {{np.mean(PSNR_measures):.2f}}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"Evaluation/measure_ssim_psnr.py\", \"w\") as f:\n",
        "    f.write(evaluation_script)\n",
        "\n",
        "# Execute the script\n",
        "!python Evaluation/measure_ssim_psnr.py"
      ],
      "metadata": {
        "id": "d3HtpG83unQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the UIQM script using the global output directory\n",
        "uiqm_script = f\"\"\"\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from os.path import join\n",
        "from ntpath import basename\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from Evaluation.uqim_utils import getUIQM\n",
        "except ImportError:\n",
        "    try:\n",
        "         from uqim_utils import getUIQM\n",
        "    except ImportError as e:\n",
        "        print(f\"Error importing uqim_utils: {{e}}\")\n",
        "        exit()\n",
        "\n",
        "def measure_UIQMs(dir_name, im_res=(256, 256)):\n",
        "    paths = sorted(glob(join(dir_name, \"*.*\")))\n",
        "    uqims = []\n",
        "    if not paths:\n",
        "        print(f\"Error: No images found in directory: {{dir_name}}\")\n",
        "        return np.array([])\n",
        "    for img_path in paths:\n",
        "        try:\n",
        "            im = Image.open(img_path).resize(im_res).convert('RGB')\n",
        "            uiqm = getUIQM(np.array(im))\n",
        "            if np.isfinite(uiqm):\n",
        "                 uqims.append(uiqm)\n",
        "        except Exception as e:\n",
        "             print(f\"Error processing {{basename(img_path)}}: {{e}}\")\n",
        "    return np.array(uqims)\n",
        "\n",
        "# Auto-populated from Cell 1 variables\n",
        "gen_dir = \"./output_{DATASET_NAME.lower()}/\"\n",
        "\n",
        "print(f\"Evaluating UIQM for: {{gen_dir}}\")\n",
        "gen_uqims = measure_UIQMs(gen_dir)\n",
        "\n",
        "if len(gen_uqims) > 0:\n",
        "    print(\"\\\\n--- UIQM Results ---\")\n",
        "    print(f\"Mean UIQM ({{len(gen_uqims)}} samples): {{np.mean(gen_uqims):.4f}}\")\n",
        "    print(f\"Std Dev: {{np.std(gen_uqims):.4f}}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"Evaluation/measure_uiqm.py\", \"w\") as f:\n",
        "    f.write(uiqm_script)\n",
        "\n",
        "# Run the evaluation\n",
        "!python Evaluation/measure_uiqm.py"
      ],
      "metadata": {
        "id": "S48Rze1Ckm6N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
