{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","mount_file_id":"1yk6vffVnYx2kM9mnU36LicpU6sjl4iE9","authorship_tag":"ABX9TyOdC0f0skFI8yC2uGr63nS5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pVQHVV4o8ChC","executionInfo":{"status":"ok","timestamp":1761020423076,"user_tz":-330,"elapsed":773373,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"3cafe2bf-24dd-47e9-f485-df90828d3e59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Found 1029 paired images.\n","Splitting into 927 training pairs and 102 testing pairs.\n","Copying training files...\n","Copying testing files...\n","\n","Dataset splitting complete!\n","Training data in: /content/GoPro_Split/train/\n","Testing data in: /content/GoPro_Split/test/\n"]}],"source":["import os\n","import random\n","import shutil\n","from glob import glob\n","from google.colab import drive\n","\n","# --- Configuration ---\n","drive.mount('/content/drive', force_remount=True)\n","gopro_base_path = \"/content/drive/My Drive/gopro_deblur\" # ADJUST THIS PATH\n","sharp_folder = os.path.join(gopro_base_path, \"sharp/images\")\n","blur_folder = os.path.join(gopro_base_path, \"blur/images\")\n","\n","# --- Output Structure ---\n","# We'll create this structure in your Colab environment\n","output_base = \"/content/GoPro_Split\"\n","train_A_path = os.path.join(output_base, \"train\", \"trainA\") # Blurry for training\n","train_B_path = os.path.join(output_base, \"train\", \"trainB\") # Sharp for training\n","test_A_path = os.path.join(output_base, \"test\", \"testA\")   # Blurry for testing\n","test_B_path = os.path.join(output_base, \"test\", \"testB\")    # Sharp for testing\n","\n","# --- Split Ratio ---\n","test_split_ratio = 0.1 # Use 10% for testing, 90% for training\n","\n","# --- Create Output Directories ---\n","os.makedirs(train_A_path, exist_ok=True)\n","os.makedirs(train_B_path, exist_ok=True)\n","os.makedirs(test_A_path, exist_ok=True)\n","os.makedirs(test_B_path, exist_ok=True)\n","\n","# --- Get Image Files ---\n","sharp_images = sorted(glob(os.path.join(sharp_folder, \"*.*\")))\n","blur_images = sorted(glob(os.path.join(blur_folder, \"*.*\")))\n","\n","if not sharp_images or not blur_images:\n","    print(f\"Error: No images found in {sharp_folder} or {blur_folder}. Check paths.\")\n","elif len(sharp_images) != len(blur_images):\n","    print(f\"Error: Mismatch in number of sharp ({len(sharp_images)}) and blur ({len(blur_images)}) images.\")\n","else:\n","    print(f\"Found {len(sharp_images)} paired images.\")\n","\n","    # --- Shuffle and Split ---\n","    paired_list = list(zip(sharp_images, blur_images))\n","    random.shuffle(paired_list) # Shuffle pairs together\n","    num_test = int(len(paired_list) * test_split_ratio)\n","    test_pairs = paired_list[:num_test]\n","    train_pairs = paired_list[num_test:]\n","\n","    print(f\"Splitting into {len(train_pairs)} training pairs and {len(test_pairs)} testing pairs.\")\n","\n","    # --- Copy Files ---\n","    def copy_pairs(pair_list, dest_A, dest_B):\n","        for sharp_path, blur_path in pair_list:\n","            base_name = os.path.basename(sharp_path) # Use sharp name for both\n","            try:\n","                shutil.copy(blur_path, os.path.join(dest_A, base_name))\n","                shutil.copy(sharp_path, os.path.join(dest_B, base_name))\n","            except Exception as e:\n","                print(f\"Error copying {base_name}: {e}\")\n","\n","    print(\"Copying training files...\")\n","    copy_pairs(train_pairs, train_A_path, train_B_path)\n","    print(\"Copying testing files...\")\n","    copy_pairs(test_pairs, test_A_path, test_B_path)\n","\n","    print(\"\\nDataset splitting complete!\")\n","    print(f\"Training data in: {output_base}/train/\")\n","    print(f\"Testing data in: {output_base}/test/\")"]},{"cell_type":"code","source":["!git clone https://github.com/AhsanBaidar/MuLA_GAN.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFWhWDAd8gGn","executionInfo":{"status":"ok","timestamp":1761020593265,"user_tz":-330,"elapsed":4976,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"01b4b006-c17f-46c0-f3f4-6b1115dd0a3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MuLA_GAN'...\n","remote: Enumerating objects: 125, done.\u001b[K\n","remote: Counting objects: 100% (97/97), done.\u001b[K\n","remote: Compressing objects: 100% (76/76), done.\u001b[K\n","remote: Total 125 (delta 30), reused 78 (delta 15), pack-reused 28 (from 1)\u001b[K\n","Receiving objects: 100% (125/125), 144.94 MiB | 38.65 MiB/s, done.\n","Resolving deltas: 100% (33/33), done.\n"]}]},{"cell_type":"code","source":["%cd MuLA_GAN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iS6XMT1RAlzH","executionInfo":{"status":"ok","timestamp":1761020760784,"user_tz":-330,"elapsed":9,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"3975218c-e7f2-4b73-facc-39d324c43e8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MuLA_GAN\n"]}]},{"cell_type":"code","source":["# --- Edit configs/train_MuLA-GAN.yaml ---\n","CONFIG_FILE=\"configs/train_MuLA-GAN.yaml\"\n","\n","# Set the ABSOLUTE path for the input training images\n","!sed -i \"s|TRAIN_INPUT: '.*'|TRAIN_INPUT: '/content/GoPro_Split/train/trainA'|\" $CONFIG_FILE\n","\n","# Set the ABSOLUTE path for the ground truth training images\n","!sed -i \"s|TRAIN_GT: '.*'|TRAIN_GT: '/content/GoPro_Split/train/trainB'|\" $CONFIG_FILE\n","\n","# The DATASET line might not even be needed now, but we'll leave it\n","# !sed -i \"s|DATASET: '.*'|DATASET: '/content/GoPro_Split'|\" $CONFIG_FILE # This line likely doesn't matter anymore\n","\n","# Optional: Set batch size if needed\n","# !sed -i 's/BATCH_SIZE: .*/BATCH_SIZE: 4/' $CONFIG_FILE\n","\n","print(\"--- Config file train_MuLA-GAN.yaml updated with ABSOLUTE paths ---\")\n","!cat $CONFIG_FILE # Verify the changes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-_tUa6BCe6L","executionInfo":{"status":"ok","timestamp":1761021130656,"user_tz":-330,"elapsed":320,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"7f89a88d-4951-49cf-d8c9-2bf155d4f367"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Config file train_MuLA-GAN.yaml updated with ABSOLUTE paths ---\n","\n","# dataset info\n","dataset_name: \"UIEB\" \n","dataset_path: \"./Dataset/\"\n","\n","# image info\n","chans: 3\n","im_width: 256\n","im_height: 256\n","\n","# other params\n","val_interval: 1000 # steps\n","ckpt_interval: 20  # epochs\n","\n","\n","\n"," \n"]}]},{"cell_type":"code","source":["%%writefile utils/data_utils.py\n","import os\n","import glob\n","import random\n","import numpy as np\n","from PIL import Image\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","import yaml # Need yaml to read the config inside the function\n","\n","class Dataloader(Dataset):\n","    def __init__(self, root, dataset_name, transforms_=None, config_path=\"configs/train_MuLA-GAN.yaml\"): # Added config_path\n","        self.transform = transforms.Compose(transforms_)\n","\n","        # --- Read config to get correct paths ---\n","        try:\n","            with open(config_path) as f:\n","                cfg = yaml.load(f, Loader=yaml.FullLoader)\n","            input_path = cfg[\"TRAIN_INPUT\"]\n","            gt_path = cfg[\"TRAIN_GT\"]\n","            # Check if paths in config are relative or absolute\n","            # If relative, join them with the root path from the main script\n","            # If absolute, use them directly\n","            if not os.path.isabs(input_path):\n","                 input_path = os.path.join(root, input_path)\n","            if not os.path.isabs(gt_path):\n","                 gt_path = os.path.join(root, gt_path)\n","\n","        except Exception as e:\n","            print(f\"Error reading config file {config_path} in Dataloader: {e}\")\n","            # Fallback to old UIEB logic if config fails? Or just error out?\n","            # Forcing error is safer:\n","            raise FileNotFoundError(f\"Could not read/parse paths from {config_path}\")\n","\n","\n","        print(\"--- Dataloader Init ---\")\n","        print(f\"Using Input Path: {input_path}\")\n","        print(f\"Using GT Path: {gt_path}\")\n","        # ---------------------------\n","\n","        self.filesA = sorted(glob.glob(input_path + \"/*.*\"))\n","        self.filesB = sorted(glob.glob(gt_path + \"/*.*\"))\n","\n","        print(f\"Found {len(self.filesA)} input files.\")\n","        print(f\"Found {len(self.filesB)} GT files.\")\n","        # --------------------------\n","\n","        if not self.filesA or not self.filesB:\n","             print(\"Error: Did not find files in one or both directories. Check paths and contents.\")\n","             self.len = 0 # Ensure len is 0 if no files found\n","        elif len(self.filesA) != len(self.filesB):\n","            print(f\"Warning: Mismatch in number of files! Input: {len(self.filesA)}, GT: {len(self.filesB)}. Using minimum.\")\n","            self.len = min(len(self.filesA), len(self.filesB))\n","        else:\n","            self.len = len(self.filesA)\n","        print(f\"Setting dataset length to: {self.len}\")\n","        print(\"-----------------------\")\n","\n","\n","    def __getitem__(self, index):\n","        # Add error checking for file reading\n","        try:\n","            img_A = Image.open(self.filesA[index % self.len]).convert('RGB') # Ensure RGB\n","            img_B = Image.open(self.filesB[index % self.len]).convert('RGB') # Ensure RGB\n","        except Exception as e:\n","            print(f\"Error opening image at index {index}: {e}\")\n","            # Return dummy data or raise error? Dummy data might hide issues.\n","            # Returning None might cause issues later. Let's return black images.\n","            dummy_tensor = torch.zeros((3, 256, 256)) # Assuming 256x256 size\n","            return {\"A\": dummy_tensor, \"B\": dummy_tensor}\n","\n","\n","        # Apply transforms only if images were loaded successfully\n","        if np.random.random() < 0.5:\n","            img_A = Image.fromarray(np.array(img_A)[:, ::-1, :], \"RGB\")\n","            img_B = Image.fromarray(np.array(img_B)[:, ::-1, :], \"RGB\")\n","\n","        try:\n","            img_A = self.transform(img_A)\n","            img_B = self.transform(img_B)\n","        except Exception as e:\n","            print(f\"Error transforming image at index {index}: {e}\")\n","            dummy_tensor = torch.zeros((3, 256, 256))\n","            return {\"A\": dummy_tensor, \"B\": dummy_tensor}\n","\n","\n","        return {\"A\": img_A, \"B\": img_B}\n","\n","    def __len__(self):\n","        # print(f\"Dataset __len__ called, returning: {self.len}\") # Optional debug\n","        return self.len\n","\n","    # --- get_file_paths function is NO LONGER USED by __init__ ---\n","    # def get_file_paths(self, root, dataset_name):\n","    #     if dataset_name=='UIEB':\n","    #         filesA, filesB = [], []\n","    #         sub_dirs = ['train']\n","    #         for sd in sub_dirs:\n","    #             filesA += sorted(glob.glob(os.path.join(root, sd, 'trainA') + \"/*.*\"))\n","    #             filesB += sorted(glob.glob(os.path.join(root, sd, 'trainB') + \"/*.*\"))\n","    #     return filesA, filesB"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNjR0Eg1COwM","executionInfo":{"status":"ok","timestamp":1761021520378,"user_tz":-330,"elapsed":17,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"87fb1d9d-a69e-4630-80ca-859c32d783be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting utils/data_utils.py\n"]}]},{"cell_type":"code","source":["%%writefile configs/train_MuLA-GAN.yaml\n","# --- Training Configuration for MuLA-GAN on GoPro ---\n","\n","# Dataset Info\n","dataset_path: '/content/GoPro_Split' # Base path for the split data\n","TRAIN_INPUT: 'train/trainA'      # Relative path to blurry training images\n","TRAIN_GT: 'train/trainB'         # Relative path to sharp training images\n","TEST_INPUT: 'test/testA'         # Relative path to blurry test images\n","TEST_GT: 'test/testB'            # Relative path to sharp test images\n","dataset_name: \"GoPro\"           # Name for the dataset\n","\n","# Image Info\n","im_width: 256                   # <<< CORRECTED KEY\n","im_height: 256                  # <<< CORRECTED KEY\n","chans: 3                        # <<< CORRECTED KEY\n","\n","# Model Info\n","MODEL_NAME: 'MuLA_GAN'\n","GENERATOR: 'mula_gan_g'\n","DISCRIMINATOR: 'mula_gan_d'\n","\n","# Training Params\n","BATCH_SIZE: 8           # Original Batch Size\n","NUM_EPOCHS: 200         # Total epochs (adjust as needed)\n","LR_G: 0.0002\n","LR_D: 0.0002\n","B1: 0.5\n","B2: 0.999\n","WEIGHT_DECAY: 0.0001\n","LAMBDA_L1: 100\n","LAMBDA_ADV: 1\n","LAMBDA_PERCEPTUAL: 10   # Ensure VGG is used in train script if > 0\n","\n","# Checkpoint/Logging Params\n","ckpt_interval: 20       # <<< CORRECTED KEY: Save model every 20 epochs\n","SAMPLE_INTERVAL: 1000   # Save sample validation images every 1000 steps (iterations)\n","LOG_INTERVAL: 50        # Print loss info every 50 steps\n","val_interval: 1000      # <<< CORRECTED KEY: Run validation every 1000 steps\n","\n","# Output Paths\n","CHECKPOINT_DIR: 'checkpoints'\n","SAMPLE_DIR: 'samples'\n","RESULTS_PATH: 'results'      # Where test.py might save output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JE5xQ71jGL2n","executionInfo":{"status":"ok","timestamp":1761022101148,"user_tz":-330,"elapsed":18,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"3ff7fac6-bc47-4b6d-bb82-e0b00abad095"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting configs/train_MuLA-GAN.yaml\n"]}]},{"cell_type":"code","source":["!python train_MuLA_GAN.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBDA25VfBfM3","executionInfo":{"status":"ok","timestamp":1761053848719,"user_tz":-330,"elapsed":25008363,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"21586c0c-f902-4ffd-f843-e3346e562ba1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","@@@@@@@@@@@@@@\n","--- Dataloader Init ---\n","Using Input Path: /content/GoPro_Split/train/trainA\n","Using GT Path: /content/GoPro_Split/train/trainB\n","Found 927 input files.\n","Found 927 GT files.\n","Setting dataset length to: 927\n","-----------------------\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/content/MuLA_GAN/train_MuLA_GAN.py:111: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n","  valid = Variable(Tensor(np.ones((imgs_distorted.size(0), *patch))), requires_grad=False)\n","[Epoch 300/301: batch 450/464] [DLoss: 0.018, GLoss: 1.970, AdvLoss: 0.988]"]}]},{"cell_type":"code","source":["# --- IMPORTANT: ---\n","# 1. Replace 'GoPro_Split' if your checkpoint folder has a different name.\n","# 2. Replace 'generator_199.pth' with the actual highest epoch number.\n","\n","!python test.py \\\n","  --weights_path \"checkpoints/GoPro/generator_300.pth\" \\\n","  --data_dir \"/content/GoPro_Split/test/testA/\" \\\n","  --sample_dir \"./output_gopro/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTGl6mrQD-iL","executionInfo":{"status":"ok","timestamp":1761054850034,"user_tz":-330,"elapsed":21486,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"ca58bb50-e124-49e7-cd58-593e154ef4ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded model from checkpoints/GoPro/generator_300.pth\n","Tested: /content/GoPro_Split/test/testA/000002.png\n","Tested: /content/GoPro_Split/test/testA/000014.png\n","Tested: /content/GoPro_Split/test/testA/000028.png\n","Tested: /content/GoPro_Split/test/testA/000033.png\n","Tested: /content/GoPro_Split/test/testA/000037.png\n","Tested: /content/GoPro_Split/test/testA/000044.png\n","Tested: /content/GoPro_Split/test/testA/000045.png\n","Tested: /content/GoPro_Split/test/testA/000064.png\n","Tested: /content/GoPro_Split/test/testA/000072.png\n","Tested: /content/GoPro_Split/test/testA/000078.png\n","Tested: /content/GoPro_Split/test/testA/000083.png\n","Tested: /content/GoPro_Split/test/testA/000093.png\n","Tested: /content/GoPro_Split/test/testA/000104.png\n","Tested: /content/GoPro_Split/test/testA/000115.png\n","Tested: /content/GoPro_Split/test/testA/000132.png\n","Tested: /content/GoPro_Split/test/testA/000143.png\n","Tested: /content/GoPro_Split/test/testA/000153.png\n","Tested: /content/GoPro_Split/test/testA/000154.png\n","Tested: /content/GoPro_Split/test/testA/000174.png\n","Tested: /content/GoPro_Split/test/testA/000175.png\n","Tested: /content/GoPro_Split/test/testA/000203.png\n","Tested: /content/GoPro_Split/test/testA/000212.png\n","Tested: /content/GoPro_Split/test/testA/000221.png\n","Tested: /content/GoPro_Split/test/testA/000248.png\n","Tested: /content/GoPro_Split/test/testA/000270.png\n","Tested: /content/GoPro_Split/test/testA/000283.png\n","Tested: /content/GoPro_Split/test/testA/000294.png\n","Tested: /content/GoPro_Split/test/testA/000329.png\n","Tested: /content/GoPro_Split/test/testA/000337.png\n","Tested: /content/GoPro_Split/test/testA/000339.png\n","Tested: /content/GoPro_Split/test/testA/000345.png\n","Tested: /content/GoPro_Split/test/testA/000552.png\n","Tested: /content/GoPro_Split/test/testA/000557.png\n","Tested: /content/GoPro_Split/test/testA/000558.png\n","Tested: /content/GoPro_Split/test/testA/000577.png\n","Tested: /content/GoPro_Split/test/testA/000578.png\n","Tested: /content/GoPro_Split/test/testA/000579.png\n","Tested: /content/GoPro_Split/test/testA/000580.png\n","Tested: /content/GoPro_Split/test/testA/000584.png\n","Tested: /content/GoPro_Split/test/testA/000590.png\n","Tested: /content/GoPro_Split/test/testA/000592.png\n","Tested: /content/GoPro_Split/test/testA/000597.png\n","Tested: /content/GoPro_Split/test/testA/000626.png\n","Tested: /content/GoPro_Split/test/testA/000634.png\n","Tested: /content/GoPro_Split/test/testA/000681.png\n","Tested: /content/GoPro_Split/test/testA/000690.png\n","Tested: /content/GoPro_Split/test/testA/000700.png\n","Tested: /content/GoPro_Split/test/testA/000723.png\n","Tested: /content/GoPro_Split/test/testA/000749.png\n","Tested: /content/GoPro_Split/test/testA/000751.png\n","Tested: /content/GoPro_Split/test/testA/000754.png\n","Tested: /content/GoPro_Split/test/testA/000966.png\n","Tested: /content/GoPro_Split/test/testA/000989.png\n","Tested: /content/GoPro_Split/test/testA/000992.png\n","Tested: /content/GoPro_Split/test/testA/001003.png\n","Tested: /content/GoPro_Split/test/testA/001007.png\n","Tested: /content/GoPro_Split/test/testA/001009.png\n","Tested: /content/GoPro_Split/test/testA/001027.png\n","Tested: /content/GoPro_Split/test/testA/001044.png\n","Tested: /content/GoPro_Split/test/testA/001049.png\n","Tested: /content/GoPro_Split/test/testA/001311.png\n","Tested: /content/GoPro_Split/test/testA/001323.png\n","Tested: /content/GoPro_Split/test/testA/001328.png\n","Tested: /content/GoPro_Split/test/testA/001337.png\n","Tested: /content/GoPro_Split/test/testA/001338.png\n","Tested: /content/GoPro_Split/test/testA/001345.png\n","Tested: /content/GoPro_Split/test/testA/001348.png\n","Tested: /content/GoPro_Split/test/testA/001372.png\n","Tested: /content/GoPro_Split/test/testA/001381.png\n","Tested: /content/GoPro_Split/test/testA/001384.png\n","Tested: /content/GoPro_Split/test/testA/001386.png\n","Tested: /content/GoPro_Split/test/testA/001399.png\n","Tested: /content/GoPro_Split/test/testA/002103.png\n","Tested: /content/GoPro_Split/test/testA/002110.png\n","Tested: /content/GoPro_Split/test/testA/002113.png\n","Tested: /content/GoPro_Split/test/testA/002142.png\n","Tested: /content/GoPro_Split/test/testA/002147.png\n","Tested: /content/GoPro_Split/test/testA/002158.png\n","Tested: /content/GoPro_Split/test/testA/002163.png\n","Tested: /content/GoPro_Split/test/testA/002181.png\n","Tested: /content/GoPro_Split/test/testA/002182.png\n","Tested: /content/GoPro_Split/test/testA/002188.png\n","Tested: /content/GoPro_Split/test/testA/002191.png\n","Tested: /content/GoPro_Split/test/testA/002197.png\n","Tested: /content/GoPro_Split/test/testA/002486.png\n","Tested: /content/GoPro_Split/test/testA/002497.png\n","Tested: /content/GoPro_Split/test/testA/002502.png\n","Tested: /content/GoPro_Split/test/testA/002518.png\n","Tested: /content/GoPro_Split/test/testA/002527.png\n","Tested: /content/GoPro_Split/test/testA/002804.png\n","Tested: /content/GoPro_Split/test/testA/002810.png\n","Tested: /content/GoPro_Split/test/testA/002812.png\n","Tested: /content/GoPro_Split/test/testA/002815.png\n","Tested: /content/GoPro_Split/test/testA/002826.png\n","Tested: /content/GoPro_Split/test/testA/002838.png\n","Tested: /content/GoPro_Split/test/testA/002844.png\n","Tested: /content/GoPro_Split/test/testA/002849.png\n","Tested: /content/GoPro_Split/test/testA/002853.png\n","Tested: /content/GoPro_Split/test/testA/002854.png\n","Tested: /content/GoPro_Split/test/testA/002855.png\n","Tested: /content/GoPro_Split/test/testA/002884.png\n","Tested: /content/GoPro_Split/test/testA/002888.png\n","\n","Total samples: 102\n","Time taken: 0 sec at 132.555 fps\n","Saved generated images in in ./output_gopro/\n","\n"]}]},{"cell_type":"code","source":["%%writefile Evaluation/measure_ssim_psnr.py\n","\"\"\"\n","# > Script for measuring quantitative performances in terms of\n","#   - Structural Similarity Metric (SSIM)\n","#   - Peak Signal to Noise Ratio (PSNR)\n","# > Maintainer: https://github.com/xahidbuffon\n","\"\"\"\n","## python libs\n","import numpy as np\n","from PIL import Image\n","from glob import glob\n","from os.path import join, exists # Added exists\n","from ntpath import basename\n","import os\n","## local libs\n","# Make sure imqual_utils is importable\n","try:\n","    # Assumes running from MuLA_GAN root\n","    from Evaluation.imqual_utils import getSSIM, getPSNR\n","except ImportError:\n","    # Try importing from current directory if run from Evaluation/\n","    try:\n","         from imqual_utils import getSSIM, getPSNR\n","    except ImportError as e:\n","        print(f\"Error importing imqual_utils: {e}\")\n","        print(\"Please ensure you are running this script from the MuLA_GAN root directory or that Evaluation is in your Python path.\")\n","        exit()\n","\n","\n","## compares avg ssim and psnr\n","def SSIMs_PSNRs(gtr_dir, gen_dir, im_res=(256, 256)):\n","    \"\"\"\n","        - gtr_dir contain ground-truths\n","        - gen_dir contain generated images\n","    \"\"\"\n","    gtr_paths = sorted(glob(join(gtr_dir, \"*.*\")))\n","    # Don't sort gen_paths here, look them up based on gtr_paths\n","    # gen_paths_all = sorted(glob(join(gen_dir, \"*.*\")))\n","\n","    print(f\"Found {len(gtr_paths)} potential ground truth images in: {gtr_dir}\")\n","    print(f\"Looking for corresponding generated images in: {gen_dir}\")\n","\n","    ssims, psnrs = [], []\n","    processed_count = 0\n","\n","    if not gtr_paths:\n","        print(f\"Error: No image files found in ground truth directory: {gtr_dir}\")\n","        return np.array([]), np.array([])\n","\n","    for gtr_path in gtr_paths:\n","        # Get base filename without extension\n","        gtr_f_base = basename(gtr_path).split('.')[0]\n","        # Construct expected generated file path (try common extensions)\n","        gen_path_expected_png = join(gen_dir, gtr_f_base + \".png\")\n","        gen_path_expected_jpg = join(gen_dir, gtr_f_base + \".jpg\")\n","        gen_path_expected_jpeg = join(gen_dir, gtr_f_base + \".jpeg\")\n","\n","        gen_path = None\n","        if exists(gen_path_expected_png):\n","            gen_path = gen_path_expected_png\n","        elif exists(gen_path_expected_jpg):\n","            gen_path = gen_path_expected_jpg\n","        elif exists(gen_path_expected_jpeg):\n","            gen_path = gen_path_expected_jpeg\n","        # Add more extensions if needed\n","\n","        if gen_path: # Check if a corresponding file was found\n","            processed_count += 1\n","            # print(f\"Processing pair: GT={gtr_path}, GEN={gen_path}\") # Debug\n","            try:\n","                r_im = Image.open(gtr_path).resize(im_res)\n","                g_im = Image.open(gen_path).resize(im_res)\n","\n","                # Ensure images are RGB before SSIM\n","                if r_im.mode != 'RGB': r_im = r_im.convert('RGB')\n","                if g_im.mode != 'RGB': g_im = g_im.convert('RGB')\n","\n","                # get ssim on RGB channels\n","                ssim_val = getSSIM(np.array(r_im), np.array(g_im))\n","                if np.isfinite(ssim_val): ssims.append(ssim_val)\n","\n","                # get psnr on L channel (grayscale)\n","                r_im_L = r_im.convert(\"L\")\n","                g_im_L = g_im.convert(\"L\")\n","                psnr_val = getPSNR(np.array(r_im_L), np.array(g_im_L))\n","                if np.isfinite(psnr_val): psnrs.append(psnr_val)\n","\n","            except Exception as e:\n","                 print(f\"Error processing {basename(gtr_path)} / {basename(gen_path)}: {e}\")\n","        # else:\n","            # print(f\"Skipping {basename(gtr_path)}: Corresponding generated file not found.\") # Debug\n","\n","\n","    if processed_count == 0:\n","        print(\"\\nError: No matching image pairs found between the two directories!\")\n","        print(\"Please check paths and ensure filenames (without extension) are identical.\")\n","        return np.array([]), np.array([]) # Return empty arrays\n","\n","    return np.array(ssims), np.array(psnrs)\n","\n","\n","# --- Define YOUR paths here ---\n","# These paths point to your GoPro split data\n","gtr_dir = \"/content/GoPro_Split/test/testB/\"  # <<< UPDATED: Path to GoPro test ground truth\n","gen_dir = \"./output_gopro/\"               # <<< UPDATED: Path to your generated GoPro test images\n","# -----------------------------\n","\n","\n","### compute SSIM and PSNR\n","SSIM_measures, PSNR_measures = SSIMs_PSNRs(gtr_dir, gen_dir)\n","\n","# Check if any valid results were returned before calculating mean/std\n","if len(SSIM_measures) > 0:\n","    print (\"\\n--- Results ---\")\n","    print (\"SSIM on {0} matched samples\".format(len(SSIM_measures)))\n","    print (\"Mean: {0:.4f} std: {1:.4f}\".format(np.mean(SSIM_measures), np.std(SSIM_measures)))\n","else:\n","    print(\"\\n--- No valid SSIM scores calculated. ---\")\n","\n","\n","if len(PSNR_measures) > 0:\n","    print (\"\\nPSNR on {0} matched samples\".format(len(PSNR_measures)))\n","    print (\"Mean: {0:.2f} std: {1:.2f}\".format(np.mean(PSNR_measures), np.std(PSNR_measures)))\n","else:\n","     print(\"\\n--- No valid PSNR scores calculated. ---\")\n","\n","if len(SSIM_measures) == 0 and len(PSNR_measures) == 0:\n","    print (\"\\n--- No results calculated. Check paths, filenames, and potential errors during processing. ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMYkHa_YB3xd","executionInfo":{"status":"ok","timestamp":1761054935197,"user_tz":-330,"elapsed":10,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"081efa81-e98b-4e6b-e4ca-934b737b4399"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Evaluation/measure_ssim_psnr.py\n"]}]},{"cell_type":"code","source":["!python Evaluation/measure_ssim_psnr.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyZTbpnrDcbP","executionInfo":{"status":"ok","timestamp":1761054953522,"user_tz":-330,"elapsed":9101,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"eca4e742-eebc-436a-d7a0-d8943f9114df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 102 potential ground truth images in: /content/GoPro_Split/test/testB/\n","Looking for corresponding generated images in: ./output_gopro/\n","\n","--- Results ---\n","SSIM on 102 matched samples\n","Mean: 0.8396 std: 0.1349\n","\n","PSNR on 102 matched samples\n","Mean: 28.09 std: 4.05\n"]}]},{"cell_type":"code","source":["%%writefile Evaluation/measure_uiqm.py\n","\"\"\"\n","# > Script for measuring quantitative performance in terms of UIQM\n","# > Maintainer: https://github.com/xahidbuffon\n","\"\"\"\n","## python libs\n","import numpy as np\n","from PIL import Image, ImageOps\n","from glob import glob\n","from os.path import join\n","from ntpath import basename\n","import os # Added os import\n","## local libs\n","# Make sure uqim_utils is importable\n","try:\n","    # Assumes running from MuLA_GAN root\n","    from Evaluation.uqim_utils import getUIQM\n","except ImportError:\n","    # Try importing from current directory if run from Evaluation/\n","    try:\n","         from uqim_utils import getUIQM\n","    except ImportError as e:\n","        print(f\"Error importing uqim_utils: {e}\")\n","        print(\"Please ensure you are running this script from the MuLA_GAN root directory or that Evaluation is in your Python path.\")\n","        exit()\n","\n","\n","def measure_UIQMs(dir_name, im_res=(256, 256)):\n","    paths = sorted(glob(join(dir_name, \"*.*\")))\n","    print(f\"Found {len(paths)} files in: {dir_name}\") # Debug print\n","    uqims = []\n","    i=0\n","    if not paths:\n","        print(f\"Error: No images found in directory: {dir_name}\")\n","        return np.array([])\n","\n","    for img_path in paths:\n","        # print(f\"Processing image {i+1}/{len(paths)}: {basename(img_path)}\") # Debug print\n","        i=i+1\n","        try:\n","            im = Image.open(img_path).resize(im_res)\n","             # Ensure image is RGB for UIQM calculation\n","            if im.mode != 'RGB': im = im.convert('RGB')\n","            im_array = np.array(im)\n","            # print(im_array.shape) # Debug print shape\n","            uiqm = getUIQM(im_array)\n","            if np.isfinite(uiqm): # Check for NaN/Inf\n","                 uqims.append(uiqm)\n","            # else:\n","                # print(f\"  -> Warning: UIQM calculation resulted in NaN/Inf for {basename(img_path)}\")\n","\n","        except Exception as e:\n","             print(f\"Error processing {basename(img_path)}: {e}\")\n","\n","    if not uqims:\n","        print(\"\\nError: UIQM calculation failed for all images.\")\n","        return np.array([])\n","\n","    return np.array(uqims)\n","\n","\n","# --- Define YOUR path here ---\n","# This path points to your generated GoPro results\n","gen_dir = \"./output_gopro/\" # <<< UPDATED\n","# -----------------------------\n","\n","# UIQMs of the enhanceded output images\n","gen_uqims = measure_UIQMs(gen_dir)\n","\n","if len(gen_uqims) > 0: # Only print if results were calculated\n","    print (\"\\n--- Results ---\")\n","    print (\"UIQM on {0} samples\".format(len(gen_uqims)))\n","    print (\"Mean: {0:.4f} std: {1:.4f}\".format(np.mean(gen_uqims), np.std(gen_uqims)))\n","else:\n","     print (\"\\n--- No UIQM results calculated. Check path and logs. ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z19M6uKCDesy","executionInfo":{"status":"ok","timestamp":1761054966399,"user_tz":-330,"elapsed":12,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"4aa2c84d-8b00-4f12-99b4-76729f5a8738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Evaluation/measure_uiqm.py\n"]}]},{"cell_type":"code","source":["!python Evaluation/measure_uiqm.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SjFmVfXDkDI","executionInfo":{"status":"ok","timestamp":1761054991581,"user_tz":-330,"elapsed":12655,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"ba917dea-a559-462e-b53e-2ab7b7a45783"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 102 files in: ./output_gopro/\n","\n","--- Results ---\n","UIQM on 102 samples\n","Mean: 3.2567 std: 0.2321\n"]}]},{"cell_type":"code","source":["!zip -r gopro_results.zip ./output_gopro/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkQIwimgDnHr","executionInfo":{"status":"ok","timestamp":1761055061958,"user_tz":-330,"elapsed":729,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"726b7f09-edc2-4bbe-c8f1-7a20933cddea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: output_gopro/ (stored 0%)\n","  adding: output_gopro/002147.png (deflated 0%)\n","  adding: output_gopro/000577.png (deflated 0%)\n","  adding: output_gopro/002812.png (deflated 0%)\n","  adding: output_gopro/000681.png (deflated 0%)\n","  adding: output_gopro/001044.png (deflated 0%)\n","  adding: output_gopro/001027.png (deflated 0%)\n","  adding: output_gopro/001386.png (deflated 0%)\n","  adding: output_gopro/000143.png (deflated 0%)\n","  adding: output_gopro/002838.png (deflated 0%)\n","  adding: output_gopro/002486.png (deflated 0%)\n","  adding: output_gopro/000002.png (deflated 0%)\n","  adding: output_gopro/000115.png (deflated 0%)\n","  adding: output_gopro/000212.png (deflated 0%)\n","  adding: output_gopro/002853.png (deflated 0%)\n","  adding: output_gopro/002855.png (deflated 0%)\n","  adding: output_gopro/000270.png (deflated 0%)\n","  adding: output_gopro/000037.png (deflated 0%)\n","  adding: output_gopro/000044.png (deflated 0%)\n","  adding: output_gopro/000248.png (deflated 0%)\n","  adding: output_gopro/002113.png (deflated 0%)\n","  adding: output_gopro/000700.png (deflated 0%)\n","  adding: output_gopro/000723.png (deflated 0%)\n","  adding: output_gopro/002188.png (deflated 0%)\n","  adding: output_gopro/001338.png (deflated 0%)\n","  adding: output_gopro/000626.png (deflated 0%)\n","  adding: output_gopro/000132.png (deflated 0%)\n","  adding: output_gopro/000580.png (deflated 0%)\n","  adding: output_gopro/002888.png (deflated 0%)\n","  adding: output_gopro/002804.png (deflated 0%)\n","  adding: output_gopro/000154.png (deflated 0%)\n","  adding: output_gopro/001345.png (deflated 0%)\n","  adding: output_gopro/000033.png (deflated 0%)\n","  adding: output_gopro/000584.png (deflated 0%)\n","  adding: output_gopro/001049.png (deflated 0%)\n","  adding: output_gopro/002197.png (deflated 0%)\n","  adding: output_gopro/000989.png (deflated 0%)\n","  adding: output_gopro/001337.png (deflated 0%)\n","  adding: output_gopro/000634.png (deflated 0%)\n","  adding: output_gopro/000590.png (deflated 0%)\n","  adding: output_gopro/000597.png (deflated 0%)\n","  adding: output_gopro/000078.png (deflated 0%)\n","  adding: output_gopro/000592.png (deflated 0%)\n","  adding: output_gopro/000337.png (deflated 0%)\n","  adding: output_gopro/001399.png (deflated 0%)\n","  adding: output_gopro/000751.png (deflated 0%)\n","  adding: output_gopro/000104.png (deflated 0%)\n","  adding: output_gopro/001328.png (deflated 0%)\n","  adding: output_gopro/002182.png (deflated 0%)\n","  adding: output_gopro/002844.png (deflated 0%)\n","  adding: output_gopro/000072.png (deflated 0%)\n","  adding: output_gopro/000339.png (deflated 0%)\n","  adding: output_gopro/000175.png (deflated 0%)\n","  adding: output_gopro/000579.png (deflated 0%)\n","  adding: output_gopro/002103.png (deflated 0%)\n","  adding: output_gopro/000083.png (deflated 0%)\n","  adding: output_gopro/000283.png (deflated 0%)\n","  adding: output_gopro/000558.png (deflated 0%)\n","  adding: output_gopro/001348.png (deflated 0%)\n","  adding: output_gopro/001372.png (deflated 0%)\n","  adding: output_gopro/000690.png (deflated 0%)\n","  adding: output_gopro/002163.png (deflated 0%)\n","  adding: output_gopro/000966.png (deflated 0%)\n","  adding: output_gopro/000294.png (deflated 0%)\n","  adding: output_gopro/000221.png (deflated 0%)\n","  adding: output_gopro/002518.png (deflated 0%)\n","  adding: output_gopro/002826.png (deflated 0%)\n","  adding: output_gopro/000028.png (deflated 0%)\n","  adding: output_gopro/001003.png (deflated 0%)\n","  adding: output_gopro/002181.png (deflated 0%)\n","  adding: output_gopro/000345.png (deflated 0%)\n","  adding: output_gopro/000014.png (deflated 0%)\n","  adding: output_gopro/002191.png (deflated 0%)\n","  adding: output_gopro/001311.png (deflated 0%)\n","  adding: output_gopro/000329.png (deflated 0%)\n","  adding: output_gopro/000992.png (deflated 0%)\n","  adding: output_gopro/001009.png (deflated 0%)\n","  adding: output_gopro/000754.png (deflated 0%)\n","  adding: output_gopro/001323.png (deflated 0%)\n","  adding: output_gopro/000578.png (deflated 0%)\n","  adding: output_gopro/002497.png (deflated 0%)\n","  adding: output_gopro/001381.png (deflated 0%)\n","  adding: output_gopro/002502.png (deflated 0%)\n","  adding: output_gopro/002854.png (deflated 0%)\n","  adding: output_gopro/000174.png (deflated 0%)\n","  adding: output_gopro/002884.png (deflated 0%)\n","  adding: output_gopro/002815.png (deflated 0%)\n","  adding: output_gopro/002110.png (deflated 0%)\n","  adding: output_gopro/002142.png (deflated 0%)\n","  adding: output_gopro/002849.png (deflated 0%)\n","  adding: output_gopro/000552.png (deflated 0%)\n","  adding: output_gopro/000064.png (deflated 0%)\n","  adding: output_gopro/000203.png (deflated 0%)\n","  adding: output_gopro/000093.png (deflated 0%)\n","  adding: output_gopro/000045.png (deflated 0%)\n","  adding: output_gopro/001384.png (deflated 0%)\n","  adding: output_gopro/002158.png (deflated 0%)\n","  adding: output_gopro/002527.png (deflated 0%)\n","  adding: output_gopro/002810.png (deflated 0%)\n","  adding: output_gopro/000153.png (deflated 0%)\n","  adding: output_gopro/000557.png (deflated 0%)\n","  adding: output_gopro/000749.png (deflated 0%)\n","  adding: output_gopro/001007.png (deflated 0%)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download('gopro_results.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"8BRpnQyoD7OJ","executionInfo":{"status":"ok","timestamp":1761055077748,"user_tz":-330,"elapsed":20,"user":{"displayName":"Dishant Roland","userId":"02650749831231510110"}},"outputId":"1fcce085-b8dc-4b43-acf0-bcb5a18a66c2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_da03255c-3ed4-4edb-85aa-46e68fa653e4\", \"gopro_results.zip\", 11851650)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"_oq9QJEaD_Ps"},"execution_count":null,"outputs":[]}]}