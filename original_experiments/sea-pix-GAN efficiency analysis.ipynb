{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Inference speed (Latency/Throughput) was benchmarked on an NVIDIA Tesla T4.\n",
        "# Results may vary depending on the specific GPU architecture and system load.\n",
        "# Complexity (GFLOPs) and Parameters remain constant at 256x256 resolution."
      ],
      "metadata": {
        "id": "FeqvJMKW318w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfzxdDBUrKlQ",
        "outputId": "30878983-6646-47f8-eeda-bb4ec59f04c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch as th\n",
        "import time\n",
        "\n",
        "class EncoderModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, leaky_relu_slope=0.2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.lrelu = nn.LeakyReLU(leaky_relu_slope)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.lrelu(x)\n",
        "        return x\n",
        "\n",
        "class FeatureMapModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, leaky_relu_slope=0.2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
        "        self.lrelu = nn.LeakyReLU(leaky_relu_slope)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.lrelu(x)\n",
        "        return x\n",
        "\n",
        "class DecoderModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.deconv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class OutputModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder model for image generation\n",
        "\n",
        "    A residual autoencoder model for image generation.\n",
        "    The final model will be an image-to-image translation model\n",
        "    that enhances underwater images.\n",
        "    \"\"\"\n",
        "    def __init__(self, DEBUG=False):\n",
        "        super().__init__()\n",
        "        self.DEBUG = DEBUG\n",
        "\n",
        "        self.EncoderLayers = nn.ModuleList([\n",
        "            EncoderModule(3, 64),\n",
        "            EncoderModule(64, 128),\n",
        "            EncoderModule(128, 256),\n",
        "            EncoderModule(256, 512),\n",
        "            EncoderModule(512, 512),\n",
        "            EncoderModule(512, 512),\n",
        "            EncoderModule(512, 512),\n",
        "            FeatureMapModule(512, 512),\n",
        "        ])\n",
        "\n",
        "        self.DecoderLayers = nn.ModuleList([\n",
        "            DecoderModule(512, 512),\n",
        "            DecoderModule(1024, 512),\n",
        "            DecoderModule(1024, 512),\n",
        "            DecoderModule(1024, 512, dropout_prob=0.0),\n",
        "            DecoderModule(1024, 256, dropout_prob=0.0),\n",
        "            DecoderModule(512, 128, dropout_prob=0.0),\n",
        "            DecoderModule(256, 64, dropout_prob=0.0),\n",
        "        ])\n",
        "\n",
        "        self.OutputLayer = OutputModule(128, 3)\n",
        "        self.tanh = nn.Tanh() #NOTE: Not actually in the paper, but required to limit values to [0,1]. This produces a valid (float) image tensor.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass for the autoencoder model.\n",
        "\n",
        "        Args:\n",
        "            x (th.Tensor): Input image tensor\n",
        "\n",
        "        Returns:\n",
        "            th.Tensor: Output image tensor\n",
        "        \"\"\"\n",
        "        # Store the activations of the encoder layers for skip connections\n",
        "        layer_outputs = []\n",
        "\n",
        "        if self.DEBUG:\n",
        "            print(\"Starting forward pass\")\n",
        "            print(x.shape)\n",
        "\n",
        "        # Encoder pass\n",
        "        for i in range(len(self.EncoderLayers)):\n",
        "            x = self.EncoderLayers[i](x)\n",
        "            if i < len(self.EncoderLayers) - 1:\n",
        "                layer_outputs.append(x)\n",
        "            if self.DEBUG:\n",
        "                print(x.shape)\n",
        "\n",
        "        if self.DEBUG:\n",
        "            print(\"Encoding complete\")\n",
        "            print(x.shape)\n",
        "\n",
        "        # Checking the shapes of the stored activations\n",
        "        #[print(\"Stored activations: \",x.shape) for x in layer_outputs]\n",
        "\n",
        "        # Decoder pass\n",
        "        for i in range(len(self.DecoderLayers)):\n",
        "\n",
        "            if i != 0:\n",
        "                # Get the appropriate encoder activation\n",
        "                s = layer_outputs.pop()\n",
        "\n",
        "                # If the shapes match, concatenate the activations\n",
        "                if x.shape == s.shape:\n",
        "                    x = th.cat((x, s), 1)\n",
        "\n",
        "                else:\n",
        "                    print(\"Error, shapes do not match\")\n",
        "                    print(\"X:\", x.shape)\n",
        "                    print(\"S:\", s.shape)\n",
        "                    return th.tensor([])\n",
        "\n",
        "            # Pass the concatenated activations through the decoder layer\n",
        "            x = self.DecoderLayers[i](x)\n",
        "            if self.DEBUG:\n",
        "                print(x.shape)\n",
        "\n",
        "        if self.DEBUG:\n",
        "            print(\"Decoding complete\")\n",
        "\n",
        "        # Perform the final deconvolution\n",
        "        x = th.cat((x, layer_outputs.pop()), 1)\n",
        "        x = self.OutputLayer(x)\n",
        "        x = self.tanh(x)\n",
        "\n",
        "        if self.DEBUG:\n",
        "            print(\"Is layer_outputs empty:\", len(layer_outputs) == 0)\n",
        "            print(x.shape)\n",
        "            print(\"Output complete\")\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "grW8eLx6tNaO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yamlpr-e3VMb",
        "outputId": "2bd3fc0d-9966-43c5-951a-70bac5a20324"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.5-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from ptflops) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->ptflops) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->ptflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.3)\n",
            "Downloading ptflops-0.7.5-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "def benchmark_efficiency():\n",
        "    # 1. Setup Environment\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Replace Autoencoder() with your specific model class\n",
        "    model = Autoencoder().to(device).eval()\n",
        "    input_shape = (3, 256, 256)\n",
        "\n",
        "    print(f\"Benchmarking on: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # 2. Complexity Analysis (Structural Metrics)\n",
        "    # We use as_strings=False to get precise numerical values\n",
        "    with torch.no_grad():\n",
        "        macs, params = get_model_complexity_info(\n",
        "            model, input_shape, as_strings=False, print_per_layer_stat=False\n",
        "        )\n",
        "\n",
        "    # 3.0x multiplier logic for Full-Stack GFLOPs\n",
        "    # (Counts Add, Multiply, and Activation as distinct operations)\n",
        "    calculated_flops = (macs * 3.0) / 1e9\n",
        "\n",
        "    # 3. Latency & Throughput (Performance Metrics)\n",
        "    iterations = 100\n",
        "    warmup = 50\n",
        "\n",
        "    # Prepare input tensor on the device\n",
        "    x = torch.randn(1, *input_shape).to(device)\n",
        "\n",
        "    # Warm-up phase to initialize CUDA kernels and clear cache\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(x)\n",
        "\n",
        "    # Ensure all kernels are finished before starting the timer\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    latencies = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(iterations):\n",
        "            start = time.time()\n",
        "\n",
        "            _ = model(x)\n",
        "\n",
        "            # Synchronize after every pass for high-precision timing\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            end = time.time()\n",
        "            latencies.append((end - start) * 1000)\n",
        "\n",
        "    avg_lat = np.mean(latencies)\n",
        "    avg_fps = 1000.0 / avg_lat\n",
        "\n",
        "    # 4. Final Output\n",
        "    print(\"\\n\" + \"=\"*45)\n",
        "    print(\"       MODEL EFFICIENCY REPORT\")\n",
        "    print(\"=\"*45)\n",
        "    print(f\"üìå Parameters:   {params / 1e6:.2f} M\")\n",
        "    print(f\"üìå GFLOPs:       {calculated_flops:.2f} G\")\n",
        "    print(f\"‚è±  Avg Latency:  {avg_lat:.2f} ms\")\n",
        "    print(f\"‚ö° Throughput:   {avg_fps:.2f} FPS\")\n",
        "    print(\"=\"*45)\n",
        "    print(\"Measurement: Standard Synchronous GPU Inference\")\n",
        "    print(\"=\"*45 + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    benchmark_efficiency()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpocKkTUstF5",
        "outputId": "cc902f2a-66c9-408f-cc60-b567f0281cab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmarking on: Tesla T4\n",
            "\n",
            "=============================================\n",
            "       MODEL EFFICIENCY REPORT\n",
            "=============================================\n",
            "üìå Parameters:   54.42 M\n",
            "üìå GFLOPs:       18.20 G\n",
            "‚è±  Avg Latency:  7.15 ms\n",
            "‚ö° Throughput:   139.95 FPS\n",
            "=============================================\n",
            "Measurement: Standard Synchronous GPU Inference\n",
            "=============================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDinQ8TtNnGd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
